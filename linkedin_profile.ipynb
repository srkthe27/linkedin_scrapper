{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e275604f",
   "metadata": {},
   "source": [
    "%pip install selenium python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64aff07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINKEDIN_EMAIL = os.getenv(\"LINKEDIN_EMAIL\")\n",
    "LINKEDIN_PASSWORD = os.getenv(\"LINKEDIN_PASSWORD\")\n",
    "PROFILE_URL = [\n",
    "    \"https://www.linkedin.com/in/akshaya-ravichandran-24671b321/\",\n",
    "    \"https://www.linkedin.com/in/subendran-s-9a3192253/\",\n",
    "    \"https://www.linkedin.com/in/vignesh-kumar-sp-1a412827b/\",\n",
    "    \"https://www.linkedin.com/in/vigneswari-d-28809027b/\",\n",
    "    \"https://www.linkedin.com/in/guru-prasath-m130105/\",\n",
    "    \"https://www.linkedin.com/in/sowmiya-thejanathan-32b0442b4/\",\n",
    "    \"https://www.linkedin.com/in/claribel-hermia/\",\n",
    "    \"https://www.linkedin.com/in/sivapriyal-karikalan-21a17332b/\",\n",
    "    \"https://www.linkedin.com/in/madhumitha-csv/\",\n",
    "    \"https://www.linkedin.com/in/dhivia-bharathi-50512827b/\",\n",
    "    \"https://www.linkedin.com/in/sivasri-v-06b49727b/\",\n",
    "    \"https://www.linkedin.com/in/swetha-r-22029126a/\",\n",
    "    \"https://www.linkedin.com/in/yuva-haran-18109827b/\",\n",
    "    \"https://www.linkedin.com/in/maadhavprasad75/\",\n",
    "    \"https://www.linkedin.com/in/vignesh19032005/\",\n",
    "    \"https://www.linkedin.com/in/kamalesh-b-14a1b32a4/\",\n",
    "    \"https://www.linkedin.com/in/visshal-prasath-m-626b97304/\",\n",
    "    \"https://www.linkedin.com/in/m-sabarish-53b703221/\",\n",
    "    \"https://www.linkedin.com/in/vasanth-v-91a13427b/\",\n",
    "    \"https://www.linkedin.com/in/hemanth-yarra/\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646547df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedInScraper:\n",
    "    def __init__(self):\n",
    "        self.setup_driver()\n",
    "        self.wait = WebDriverWait(self.driver, 20)\n",
    "        \n",
    "    def setup_driver(self):\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        options.add_argument('--start-maximized')\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option('useAutomationExtension', False)\n",
    "        self.driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "    def human_delay(self, min_sec=1, max_sec=3):\n",
    "        time.sleep(random.uniform(min_sec, max_sec))\n",
    "        \n",
    "    def smooth_scroll(self, scrolls=5):\n",
    "        for i in range(scrolls):\n",
    "            scroll_height = 800 + random.randint(-100, 100)\n",
    "            self.driver.execute_script(f\"window.scrollBy(0, {scroll_height});\")\n",
    "            self.human_delay(0.5, 1.5)\n",
    "        self.driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "        self.human_delay(1, 2)\n",
    "    \n",
    "    def login(self, email, password):\n",
    "        try:\n",
    "            logger.info(\"Logging into LinkedIn...\")\n",
    "            self.driver.get(\"https://www.linkedin.com/login\")\n",
    "            self.wait.until(EC.presence_of_element_located((By.ID, \"username\")))\n",
    "            username_field = self.driver.find_element(By.ID, \"username\")\n",
    "            for char in email:\n",
    "                username_field.send_keys(char)\n",
    "                time.sleep(random.uniform(0.05, 0.15))\n",
    "            self.human_delay(0.5, 1)\n",
    "            password_field = self.driver.find_element(By.ID, \"password\")\n",
    "            for char in password:\n",
    "                password_field.send_keys(char)\n",
    "                time.sleep(random.uniform(0.05, 0.15))\n",
    "            self.human_delay(0.5, 1)\n",
    "            self.driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
    "            self.human_delay(3, 5)\n",
    "            logger.info(\"Successfully logged in!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Login failed: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def safe_find_element(self, by, selector, multiple=False):\n",
    "        try:\n",
    "            if multiple:\n",
    "                elements = self.driver.find_elements(by, selector)\n",
    "                return [el.text.strip() for el in elements if el.text.strip()]\n",
    "            else:\n",
    "                element = self.driver.find_element(by, selector)\n",
    "                return element.text.strip()\n",
    "        except (NoSuchElementException, TimeoutException):\n",
    "            return [] if multiple else \"\"\n",
    "    \n",
    "    def extract_basic_info(self):\n",
    "        data = {}\n",
    "        name_selectors = [\n",
    "            (By.CSS_SELECTOR, \"h1.text-heading-xlarge\"),\n",
    "            (By.XPATH, \"//h1[contains(@class, 'text-heading-xlarge')]\"),\n",
    "            (By.CSS_SELECTOR, \"div.mt2.relative h1\")\n",
    "        ]\n",
    "        for by, selector in name_selectors:\n",
    "            data['name'] = self.safe_find_element(by, selector)\n",
    "            if data['name']:\n",
    "                break\n",
    "        \n",
    "        # Headline\n",
    "        headline_selectors = [\n",
    "            (By.CSS_SELECTOR, \"div.text-body-medium.break-words\"),\n",
    "            (By.XPATH, \"//div[contains(@class, 'text-body-medium')]\"),\n",
    "        ]\n",
    "        \n",
    "        for by, selector in headline_selectors:\n",
    "            data['headline'] = self.safe_find_element(by, selector)\n",
    "            if data['headline']:\n",
    "                break\n",
    "        location_selectors = [\n",
    "            (By.CSS_SELECTOR, \"span.text-body-small.inline.t-black--light.break-words\"),\n",
    "            (By.XPATH, \"//span[contains(@class, 'text-body-small') and contains(@class, 't-black--light')]\"),\n",
    "        ]\n",
    "        \n",
    "        for by, selector in location_selectors:\n",
    "            data['location'] = self.safe_find_element(by, selector)\n",
    "            if data['location']:\n",
    "                break\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def extract_about(self):\n",
    "        try:\n",
    "            show_more_buttons = self.driver.find_elements(\n",
    "                By.XPATH, \n",
    "                \"//button[contains(@aria-label, 'Show more') or contains(@aria-label, 'more')]\"\n",
    "            )\n",
    "            if show_more_buttons:\n",
    "                self.driver.execute_script(\"arguments[0].click();\", show_more_buttons[0])\n",
    "                self.human_delay(0.5, 1)\n",
    "        except:\n",
    "            pass\n",
    "        about_selectors = [\n",
    "            (By.CSS_SELECTOR, \"div.display-flex.ph5.pv3 div.inline-show-more-text span[aria-hidden='true']\"),\n",
    "            (By.XPATH, \"//section[contains(@class, 'artdeco-card')]//div[contains(@class, 'inline-show-more-text')]\"),\n",
    "        ]\n",
    "        for by, selector in about_selectors:\n",
    "            about = self.safe_find_element(by, selector)\n",
    "            if about:\n",
    "                return about\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    def extract_experience(self):\n",
    "        experiences = []\n",
    "        try:\n",
    "            exp_items = self.driver.find_elements(\n",
    "                By.XPATH,\n",
    "                \"//section[contains(@id, 'experience')]//ul/li[contains(@class, 'artdeco-list__item')]\"\n",
    "            )\n",
    "            for item in exp_items[:5]:\n",
    "                try:\n",
    "                    title = self.safe_find_element(\n",
    "                        By.CSS_SELECTOR,\n",
    "                        \"div.display-flex.flex-column.full-width span[aria-hidden='true']\",\n",
    "                    ) if item else \"\"\n",
    "                    company = \"\"\n",
    "                    company_elements = item.find_elements(\n",
    "                        By.CSS_SELECTOR,\n",
    "                        \"span.t-14.t-normal span[aria-hidden='true']\"\n",
    "                    )\n",
    "                    if company_elements and len(company_elements) > 0:\n",
    "                        company = company_elements[0].text.strip()\n",
    "                    duration = \"\"\n",
    "                    duration_elements = item.find_elements(\n",
    "                        By.CSS_SELECTOR,\n",
    "                        \"span.t-14.t-normal.t-black--light span[aria-hidden='true']\"\n",
    "                    )\n",
    "                    if duration_elements and len(duration_elements) > 0:\n",
    "                        duration = duration_elements[0].text.strip()\n",
    "                    if title or company:\n",
    "                        exp_text = f\"{title} at {company}\" if title and company else title or company\n",
    "                        if duration:\n",
    "                            exp_text += f\" ({duration})\"\n",
    "                        experiences.append(exp_text)\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Error extracting experience item: {str(e)}\")\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error in experience section: {str(e)}\")\n",
    "        \n",
    "        return experiences\n",
    "    \n",
    "    def extract_education(self):\n",
    "        educations = []\n",
    "        try:\n",
    "            edu_items = self.driver.find_elements(\n",
    "                By.XPATH,\n",
    "                \"//section[contains(@id, 'education')]//ul/li[contains(@class, 'artdeco-list__item')]\"\n",
    "            )\n",
    "            for item in edu_items[:3]:\n",
    "                try:\n",
    "                    edu_parts = item.find_elements(\n",
    "                        By.CSS_SELECTOR,\n",
    "                        \"span[aria-hidden='true']\"\n",
    "                    )\n",
    "                    if edu_parts:\n",
    "                        edu_text = \" - \".join([part.text.strip() for part in edu_parts[:3] if part.text.strip()])\n",
    "                        if edu_text:\n",
    "                            educations.append(edu_text)\n",
    "                except Exception as e:\n",
    "                    logger.debug(f\"Error extracting education item: {str(e)}\")\n",
    "                    continue\n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error in education section: {str(e)}\")\n",
    "        \n",
    "        return educations\n",
    "    \n",
    "    def extract_skills(self):\n",
    "        skills = []\n",
    "        try:\n",
    "            show_all_buttons = self.driver.find_elements(\n",
    "                By.XPATH,\n",
    "                \"//section[contains(@id, 'skills')]//a[contains(@href, 'skills')]\"\n",
    "            )\n",
    "            if show_all_buttons:\n",
    "                self.driver.execute_script(\"arguments[0].click();\", show_all_buttons[0])\n",
    "                self.human_delay(2, 3)\n",
    "                skill_elements = self.driver.find_elements(\n",
    "                    By.XPATH,\n",
    "                    \"//div[contains(@class, 'scaffold-finite-scroll')]//span[contains(@class, 't-bold')]\"\n",
    "                )\n",
    "                skills = [el.text.strip() for el in skill_elements[:20] if el.text.strip()]\n",
    "                try:\n",
    "                    close_button = self.driver.find_element(\n",
    "                        By.XPATH,\n",
    "                        \"//button[@aria-label='Dismiss']\"\n",
    "                    )\n",
    "                    close_button.click()\n",
    "                    self.human_delay(0.5, 1)\n",
    "                except:\n",
    "                    pass\n",
    "            if not skills:\n",
    "                skills = self.safe_find_element(\n",
    "                    By.XPATH,\n",
    "                    \"//section[contains(@id, 'skills')]//span[contains(@class, 't-bold')]\",\n",
    "                    multiple=True\n",
    "                )[:20]\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.debug(f\"Error extracting skills: {str(e)}\")\n",
    "        \n",
    "        return skills\n",
    "    \n",
    "    def scrape_profile(self, profile_url):\n",
    "        logger.info(f\"Scraping profile: {profile_url}\")\n",
    "        \n",
    "        try:\n",
    "            self.driver.get(profile_url)\n",
    "            self.wait.until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
    "            self.human_delay(2, 3)\n",
    "            self.smooth_scroll(scrolls=8)\n",
    "            data = {\"profile_url\": profile_url}\n",
    "            basic_info = self.extract_basic_info()\n",
    "            data.update(basic_info)\n",
    "            data['about'] = self.extract_about()\n",
    "            experiences = self.extract_experience()\n",
    "            data['exp_title'] = experiences[0] if experiences else \"\"\n",
    "            data['exp_company'] = experiences[1] if len(experiences) > 1 else \"\"\n",
    "            data['experience_full'] = \" | \".join(experiences)\n",
    "            educations = self.extract_education()\n",
    "            data['education'] = educations[0] if educations else \"\"\n",
    "            data['education_full'] = \" | \".join(educations)\n",
    "            skills = self.extract_skills()\n",
    "            data['skills'] = \", \".join(skills[:10]) if skills else \"\"\n",
    "            data['skills_full'] = \", \".join(skills)\n",
    "\n",
    "            logger.info(f\"Successfully scraped: {data.get('name', 'Unknown')}\")\n",
    "            return data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error scraping {profile_url}: {str(e)}\")\n",
    "            return {\"profile_url\": profile_url, \"error\": str(e)}\n",
    "    \n",
    "    def save_to_csv(self, data, filename=\"linkedin_scraped_enhanced.csv\"):\n",
    "        if not data:\n",
    "            return\n",
    "        file_exists = os.path.isfile(filename)\n",
    "        fieldnames = [\n",
    "            'profile_url', 'name', 'headline', 'location', 'about',\n",
    "            'exp_title', 'exp_company', 'experience_full',\n",
    "            'education', 'education_full', 'skills', 'skills_full'\n",
    "        ]\n",
    "        \n",
    "        with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            writer.writerow(data)\n",
    "        logger.info(f\"Data saved to {filename}\")\n",
    "    \n",
    "    def run(self, profile_urls):\n",
    "        try:\n",
    "            self.login(LINKEDIN_EMAIL, LINKEDIN_PASSWORD)\n",
    "            for i, url in enumerate(profile_urls, 1):\n",
    "                logger.info(f\"Processing profile {i}/{len(profile_urls)}\")\n",
    "                \n",
    "                data = self.scrape_profile(url)\n",
    "                self.save_to_csv(data)\n",
    "                if i < len(profile_urls):\n",
    "                    delay = random.uniform(5, 10)\n",
    "                    logger.info(f\"Waiting {delay:.1f} seconds before next profile...\")\n",
    "                    time.sleep(delay)\n",
    "            \n",
    "            logger.info(\"Scraping completed successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Scraping failed: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self.driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b89b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 14:41:14,172 - INFO - Logging into LinkedIn...\n",
      "2025-11-08 14:43:33,318 - INFO - Successfully logged in!\n",
      "2025-11-08 14:43:33,319 - INFO - Processing profile 1/20\n",
      "2025-11-08 14:43:33,320 - INFO - Scraping profile: https://www.linkedin.com/in/akshaya-ravichandran-24671b321/\n",
      "2025-11-08 14:44:03,110 - INFO - Successfully scraped: Akshaya Ravichandran\n",
      "2025-11-08 14:44:03,112 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:44:03,113 - INFO - Waiting 7.4 seconds before next profile...\n",
      "2025-11-08 14:44:10,510 - INFO - Processing profile 2/20\n",
      "2025-11-08 14:44:10,513 - INFO - Scraping profile: https://www.linkedin.com/in/subendran-s-9a3192253/\n",
      "2025-11-08 14:44:25,734 - INFO - Successfully scraped: Subendran S\n",
      "2025-11-08 14:44:25,737 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:44:25,738 - INFO - Waiting 9.7 seconds before next profile...\n",
      "2025-11-08 14:44:35,465 - INFO - Processing profile 3/20\n",
      "2025-11-08 14:44:35,466 - INFO - Scraping profile: https://www.linkedin.com/in/vignesh-kumar-sp-1a412827b/\n",
      "2025-11-08 14:44:50,126 - INFO - Successfully scraped: VIGNESH KUMAR SP\n",
      "2025-11-08 14:44:50,128 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:44:50,128 - INFO - Waiting 5.2 seconds before next profile...\n",
      "2025-11-08 14:44:55,311 - INFO - Processing profile 4/20\n",
      "2025-11-08 14:44:55,311 - INFO - Scraping profile: https://www.linkedin.com/in/vigneswari-d-28809027b/\n",
      "2025-11-08 14:45:10,296 - INFO - Successfully scraped: Vigneswari D\n",
      "2025-11-08 14:45:10,298 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:45:10,299 - INFO - Waiting 6.5 seconds before next profile...\n",
      "2025-11-08 14:45:16,846 - INFO - Processing profile 5/20\n",
      "2025-11-08 14:45:16,847 - INFO - Scraping profile: https://www.linkedin.com/in/guru-prasath-m130105/\n",
      "2025-11-08 14:45:32,422 - INFO - Successfully scraped: Guru Prasath\n",
      "2025-11-08 14:45:32,423 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:45:32,423 - INFO - Waiting 8.1 seconds before next profile...\n",
      "2025-11-08 14:45:40,574 - INFO - Processing profile 6/20\n",
      "2025-11-08 14:45:40,575 - INFO - Scraping profile: https://www.linkedin.com/in/sowmiya-thejanathan-32b0442b4/\n",
      "2025-11-08 14:45:55,892 - INFO - Successfully scraped: Sowmiya Thejanathan\n",
      "2025-11-08 14:45:55,894 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:45:55,895 - INFO - Waiting 9.1 seconds before next profile...\n",
      "2025-11-08 14:46:05,020 - INFO - Processing profile 7/20\n",
      "2025-11-08 14:46:05,021 - INFO - Scraping profile: https://www.linkedin.com/in/claribel-hermia/\n",
      "2025-11-08 14:46:19,612 - INFO - Successfully scraped: Claribel Hermia\n",
      "2025-11-08 14:46:19,613 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:46:19,614 - INFO - Waiting 5.4 seconds before next profile...\n",
      "2025-11-08 14:46:25,025 - INFO - Processing profile 8/20\n",
      "2025-11-08 14:46:25,027 - INFO - Scraping profile: https://www.linkedin.com/in/sivapriyal-karikalan-21a17332b/\n",
      "2025-11-08 14:46:38,968 - INFO - Successfully scraped: Sivapriyal Karikalan\n",
      "2025-11-08 14:46:38,969 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:46:38,970 - INFO - Waiting 7.7 seconds before next profile...\n",
      "2025-11-08 14:46:46,689 - INFO - Processing profile 9/20\n",
      "2025-11-08 14:46:46,689 - INFO - Scraping profile: https://www.linkedin.com/in/madhumitha-csv/\n",
      "2025-11-08 14:47:01,420 - INFO - Successfully scraped: Madhumitha Chandrasekaran\n",
      "2025-11-08 14:47:01,421 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:47:01,421 - INFO - Waiting 7.1 seconds before next profile...\n",
      "2025-11-08 14:47:08,570 - INFO - Processing profile 10/20\n",
      "2025-11-08 14:47:08,571 - INFO - Scraping profile: https://www.linkedin.com/in/dhivia-bharathi-50512827b/\n",
      "2025-11-08 14:47:23,565 - INFO - Successfully scraped: Dhivia bharathi\n",
      "2025-11-08 14:47:23,566 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:47:23,567 - INFO - Waiting 7.5 seconds before next profile...\n",
      "2025-11-08 14:47:31,086 - INFO - Processing profile 11/20\n",
      "2025-11-08 14:47:31,086 - INFO - Scraping profile: https://www.linkedin.com/in/sivasri-v-06b49727b/\n",
      "2025-11-08 14:47:45,695 - INFO - Successfully scraped: Sivasri V\n",
      "2025-11-08 14:47:45,696 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:47:45,697 - INFO - Waiting 5.4 seconds before next profile...\n",
      "2025-11-08 14:47:51,142 - INFO - Processing profile 12/20\n",
      "2025-11-08 14:47:51,143 - INFO - Scraping profile: https://www.linkedin.com/in/swetha-r-22029126a/\n",
      "2025-11-08 14:48:04,828 - INFO - Successfully scraped: Swetha R\n",
      "2025-11-08 14:48:04,829 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:48:04,830 - INFO - Waiting 9.4 seconds before next profile...\n",
      "2025-11-08 14:48:14,201 - INFO - Processing profile 13/20\n",
      "2025-11-08 14:48:14,204 - INFO - Scraping profile: https://www.linkedin.com/in/yuva-haran-18109827b/\n",
      "2025-11-08 14:48:30,744 - INFO - Successfully scraped: YUVA HARAN\n",
      "2025-11-08 14:48:30,746 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:48:30,746 - INFO - Waiting 7.1 seconds before next profile...\n",
      "2025-11-08 14:48:37,891 - INFO - Processing profile 14/20\n",
      "2025-11-08 14:48:37,892 - INFO - Scraping profile: https://www.linkedin.com/in/maadhavprasad75/\n",
      "2025-11-08 14:48:52,066 - INFO - Successfully scraped: Maadhav Prasad\n",
      "2025-11-08 14:48:52,068 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:48:52,068 - INFO - Waiting 6.2 seconds before next profile...\n",
      "2025-11-08 14:48:58,316 - INFO - Processing profile 15/20\n",
      "2025-11-08 14:48:58,316 - INFO - Scraping profile: https://www.linkedin.com/in/vignesh19032005/\n",
      "2025-11-08 14:49:15,606 - INFO - Successfully scraped: Vignesh L\n",
      "2025-11-08 14:49:15,607 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:49:15,608 - INFO - Waiting 7.3 seconds before next profile...\n",
      "2025-11-08 14:49:22,948 - INFO - Processing profile 16/20\n",
      "2025-11-08 14:49:22,949 - INFO - Scraping profile: https://www.linkedin.com/in/kamalesh-b-14a1b32a4/\n",
      "2025-11-08 14:49:40,268 - INFO - Successfully scraped: Kamalesh B\n",
      "2025-11-08 14:49:40,269 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:49:40,270 - INFO - Waiting 8.2 seconds before next profile...\n",
      "2025-11-08 14:49:48,463 - INFO - Processing profile 17/20\n",
      "2025-11-08 14:49:48,464 - INFO - Scraping profile: https://www.linkedin.com/in/visshal-prasath-m-626b97304/\n",
      "2025-11-08 14:50:02,325 - INFO - Successfully scraped: VISSHAL PRASATH.M\n",
      "2025-11-08 14:50:02,326 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:50:02,327 - INFO - Waiting 5.7 seconds before next profile...\n",
      "2025-11-08 14:50:08,023 - INFO - Processing profile 18/20\n",
      "2025-11-08 14:50:08,026 - INFO - Scraping profile: https://www.linkedin.com/in/m-sabarish-53b703221/\n",
      "2025-11-08 14:51:03,370 - INFO - Successfully scraped: M. Sabarish\n",
      "2025-11-08 14:51:03,372 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:51:03,373 - INFO - Waiting 9.4 seconds before next profile...\n",
      "2025-11-08 14:51:12,760 - INFO - Processing profile 19/20\n",
      "2025-11-08 14:51:12,764 - INFO - Scraping profile: https://www.linkedin.com/in/vasanth-v-91a13427b/\n",
      "2025-11-08 14:51:27,551 - INFO - Successfully scraped: Vasanth V\n",
      "2025-11-08 14:51:27,552 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:51:27,554 - INFO - Waiting 9.9 seconds before next profile...\n",
      "2025-11-08 14:51:37,514 - INFO - Processing profile 20/20\n",
      "2025-11-08 14:51:37,520 - INFO - Scraping profile: https://www.linkedin.com/in/hemanth-yarra/\n",
      "2025-11-08 14:51:53,285 - INFO - Successfully scraped: Hemanth Yarra\n",
      "2025-11-08 14:51:53,288 - INFO - Data saved to linkedin_scraped_enhanced.csv\n",
      "2025-11-08 14:51:53,290 - INFO - Scraping completed successfully!\n"
     ]
    }
   ],
   "source": [
    "if not LINKEDIN_EMAIL or not LINKEDIN_PASSWORD:\n",
    "    logger.error(\"LinkedIn credentials not found in .env file\")\n",
    "    exit(1)\n",
    "    \n",
    "if not PROFILE_URL:\n",
    "    logger.warning(\"No profile URLs provided. Please add URLs to PROFILE_URLS list.\")\n",
    "    exit(1)\n",
    "    \n",
    "scraper = LinkedInScraper()\n",
    "scraper.run(PROFILE_URL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
